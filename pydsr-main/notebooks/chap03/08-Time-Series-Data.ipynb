{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "Pandas was originally developed in the context of financial modeling, and its time series tools are particularly comprehensive and powerful. Whether you're analyzing stock prices, monitoring server logs, studying climate patterns, or tracking user engagement metrics, working with dates and times is a fundamental skill in data science. As we will see during the course of this section, Pandas provides intuitive tools for parsing, manipulating, and analyzing temporal data that make it an ideal choice for time series analysis.\n",
    "\n",
    "A `DatetimeIndex` can be thought of as a specialized version of a Pandas `Index` that understands the semantics of time. Just as a regular Index allows fast lookups by label, a DatetimeIndex enables slicing by date strings, automatic frequency detection, and time-aware operations like resampling. Throughout this section, we will work primarily with real-world data—including US birth records and the Titanic passenger manifest—to demonstrate these capabilities in realistic contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options for cleaner output\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Converting Strings to Datetime\n",
    "\n",
    "One of the most common challenges when working with real-world data is that dates often arrive as strings in various formats—\"2024-01-15\", \"January 15, 2024\", \"15/01/2024\", and countless others. Before we can leverage Pandas' time series capabilities, we need to convert these strings into proper datetime objects. The `pd.to_datetime()` function is Pandas' Swiss Army knife for datetime conversion; you can think of it as a universal translator that understands most common date formats and converts them into a standardized representation.\n",
    "\n",
    "Let's start with the simplest case—converting a single date string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a single date string\n",
    "date = pd.to_datetime('2024-03-15')\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "The result is a `Timestamp` object—Pandas' fundamental unit for representing a single point in time. Notice that Pandas correctly inferred the year, month, and day from the ISO format string. What makes `pd.to_datetime()` particularly convenient is its ability to handle many common formats automatically, without explicit format specification. This flexibility comes from sophisticated parsing logic that recognizes patterns in date strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas handles many common formats automatically\n",
    "dates_various = [\n",
    "    '2024-03-15',          # ISO format\n",
    "    'March 15, 2024',      # Full month name\n",
    "    '15-Mar-2024',         # Abbreviated month\n",
    "    '03/15/2024',          # US format\n",
    "]\n",
    "\n",
    "for d in dates_various:\n",
    "    print(f\"{d:20} -> {pd.to_datetime(d)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### Handling Ambiguous Date Formats\n",
    "\n",
    "Keep in mind that some date formats can be genuinely ambiguous. Is \"01/02/2024\" January 2nd or February 1st? By default, Pandas assumes US conventions (month first), but you can control this behavior with the `dayfirst` parameter. This is particularly important when working with data from international sources where day-month-year ordering is standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambiguous date - default assumes month first (US convention)\n",
    "print(\"Default (US):\", pd.to_datetime('01/02/2024'))\n",
    "\n",
    "# Explicitly specify day-first for international format\n",
    "print(\"Day first:   \", pd.to_datetime('01/02/2024', dayfirst=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Specifying Exact Formats\n",
    "\n",
    "For maximum control and performance—especially when parsing large datasets—you can specify the exact format using the `format` parameter with Python's strftime directives. This approach not only eliminates ambiguity but can significantly speed up parsing because Pandas doesn't need to infer the format for each value. The format string uses codes like `%Y` for four-digit year, `%m` for zero-padded month, and `%d` for zero-padded day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom format specification\n",
    "pd.to_datetime('15-03-2024', format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a Series of date strings\n",
    "date_strings = pd.Series(['2024-01-15', '2024-02-20', '2024-03-25', '2024-04-30'])\n",
    "dates = pd.to_datetime(date_strings)\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "The result is a `DatetimeIndex`, which is Pandas' specialized index type for datetime data. This index enables powerful time-based operations that we'll explore throughout this section. When applied to a Series column in a DataFrame, the result will be a Series with `datetime64[ns]` dtype, which supports all the same operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Working with Real Data: US Births Dataset\n",
    "\n",
    "Let's apply these datetime conversion concepts to real data. The US births dataset contains daily birth counts from 1969 to 1988, providing an excellent opportunity to work with temporal patterns. We'll load this data and convert the separate year, month, and day columns into a proper datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load US births data\n",
    "births_raw = pd.read_csv('https://raw.githubusercontent.com/jakevdp/data-CDCbirths/master/births.csv')\n",
    "print(f\"Raw dataset: {len(births_raw):,} rows\")\n",
    "\n",
    "# Clean the data: remove rows with invalid days (99 = unknown, NaN = missing)\n",
    "# and aggregate by date (combining male/female counts)\n",
    "births = births_raw[births_raw['day'].between(1, 31)].copy()\n",
    "births = births.groupby(['year', 'month', 'day'])['births'].sum().reset_index()\n",
    "print(f\"Cleaned dataset: {len(births):,} rows\")\n",
    "births.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "The data has separate columns for year, month, and day. To create a proper datetime index, we can construct date strings and convert them, or use the more elegant approach of passing a dictionary of components to `pd.to_datetime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime from component columns\n",
    "# Use errors='coerce' to handle invalid dates like Feb 30, then drop them\n",
    "births['date'] = pd.to_datetime(\n",
    "    births['year'].astype(str) + '-' + \n",
    "    births['month'].astype(str).str.zfill(2) + '-' + \n",
    "    births['day'].astype(int).astype(str).str.zfill(2),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Remove any rows with invalid dates (NaT)\n",
    "births = births.dropna(subset=['date'])\n",
    "\n",
    "# Set as index\n",
    "births = births.set_index('date')\n",
    "print(f\"Final dataset: {len(births):,} rows with valid dates\")\n",
    "births.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Extracting Date Components with the .dt Accessor\n",
    "\n",
    "Once you have datetime data, you can easily extract individual components using the `.dt` accessor. This is remarkably useful for creating features for analysis or visualization. The accessor provides properties for year, month, day, day of week, and many more temporal attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract various components from the index\n",
    "print(\"Year:        \", births.index.year[:5].values)\n",
    "print(\"Month:       \", births.index.month[:5].values)\n",
    "print(\"Day:         \", births.index.day[:5].values)\n",
    "print(\"Day of week: \", births.index.dayofweek[:5].values)  # Monday=0, Sunday=6\n",
    "print(\"Day name:    \", births.index.day_name()[:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "For a Series with datetime dtype (rather than a DatetimeIndex), you would use the `.dt` accessor instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series with datetime values to demonstrate .dt accessor\n",
    "dates = pd.to_datetime(['2024-03-15 14:30:00', '2024-06-20 09:15:00', '2024-12-25 18:45:00'])\n",
    "s = pd.Series(dates)\n",
    "\n",
    "# Extract various components using .dt accessor\n",
    "print(\"Year:        \", s.dt.year.values)\n",
    "print(\"Month:       \", s.dt.month.values)\n",
    "print(\"Day:         \", s.dt.day.values)\n",
    "print(\"Day of week: \", s.dt.dayofweek.values)\n",
    "print(\"Day name:    \", s.dt.day_name().values)\n",
    "print(\"Hour:        \", s.dt.hour.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Creating Date Ranges\n",
    "\n",
    "When building time series data or creating regular temporal intervals, `pd.date_range()` is an indispensable tool. You can think of it as the datetime equivalent of `range()` for integers—it generates a sequence of evenly spaced datetime values. This is particularly useful for creating time indices, generating test data, or filling in missing dates in incomplete time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of daily dates\n",
    "pd.date_range(start='2024-01-01', end='2024-01-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, specify start and number of periods\n",
    "pd.date_range(start='2024-01-01', periods=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### Frequency Specifications\n",
    "\n",
    "The `freq` parameter controls the spacing between dates. Pandas uses intuitive frequency aliases—'D' for day, 'h' for hour, 'W' for week, and so on. The following table summarizes the most commonly used frequency codes:\n",
    "\n",
    "| Alias | Description | Example |\n",
    "|-------|-------------|--------|\n",
    "| `D` | Calendar day | Daily data |\n",
    "| `B` | Business day | Weekdays only |\n",
    "| `W` | Week (Sunday) | Weekly aggregation |\n",
    "| `ME` | Month end | Monthly reports |\n",
    "| `MS` | Month start | Monthly periods |\n",
    "| `QE` | Quarter end | Quarterly financials |\n",
    "| `YE` | Year end | Annual summaries |\n",
    "| `h` | Hour | Intraday data |\n",
    "| `min` | Minute | High-frequency data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly frequency\n",
    "print(\"Hourly:\")\n",
    "print(pd.date_range('2024-01-01', periods=5, freq='h'))\n",
    "\n",
    "# Weekly frequency (starting on Sunday by default)\n",
    "print(\"\\nWeekly:\")\n",
    "print(pd.date_range('2024-01-01', periods=5, freq='W'))\n",
    "\n",
    "# Monthly frequency (month end)\n",
    "print(\"\\nMonthly (month end):\")\n",
    "print(pd.date_range('2024-01-01', periods=5, freq='ME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business days only (excludes weekends)\n",
    "print(\"Business days:\")\n",
    "print(pd.date_range('2024-01-01', periods=10, freq='B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "Notice that January 6-7 (Saturday-Sunday) are skipped when using the 'B' (business day) frequency. This is particularly useful for financial data analysis where markets are closed on weekends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom frequencies: every 6 hours, quarterly start\n",
    "print(\"Every 6 hours:\")\n",
    "print(pd.date_range('2024-01-01', periods=5, freq='6h'))\n",
    "\n",
    "print(\"\\nQuarterly (quarter start):\")\n",
    "print(pd.date_range('2024-01-01', periods=4, freq='QS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Time Series Indexing and Slicing\n",
    "\n",
    "From what we've seen so far, we can create datetime values and ranges. Now let's explore how to use datetime as an index—this is where Pandas' time series capabilities truly shine. When a Series or DataFrame has a `DatetimeIndex`, Pandas enables intuitive string-based slicing and partial string matching that makes temporal data manipulation remarkably convenient.\n",
    "\n",
    "Let's work with the US births data we loaded earlier to demonstrate these capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our births DataFrame already has a DatetimeIndex\n",
    "print(f\"Index type: {type(births.index).__name__}\")\n",
    "print(f\"Date range: {births.index.min()} to {births.index.max()}\")\n",
    "births['births'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific date using string\n",
    "births.loc['1988-08-15', 'births']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "### Partial String Indexing\n",
    "\n",
    "One of the most powerful features of `DatetimeIndex` is *partial string indexing*. You can select all data for a particular year, month, or any partial specification. This works because Pandas interprets the partial date string and matches all index values that fall within that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all data from March 1988\n",
    "births.loc['1988-03', 'births']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all data from 1985\n",
    "births.loc['1985', 'births'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice from one date to another\n",
    "births.loc['1988-02-15':'1988-03-05', 'births']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "Notice that unlike Python's standard slicing, datetime slicing in Pandas is *inclusive* on both ends—both the start and end dates are included in the result. This behavior aligns with how we typically think about date ranges: \"from February 15th to March 5th\" naturally includes both boundary dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "### Boolean Selection with Datetime\n",
    "\n",
    "You can also use boolean conditions to filter time series data based on date components. The index attributes like `month`, `dayofweek`, and `year` return arrays that can be used for boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only weekdays (Monday=0 through Friday=4)\n",
    "weekday_mask = births.index.dayofweek < 5\n",
    "births_weekdays = births[weekday_mask]\n",
    "print(f\"Original length:  {len(births):,}\")\n",
    "print(f\"Weekdays only:    {len(births_weekdays):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data from summer months (June, July, August)\n",
    "summer_mask = births.index.month.isin([6, 7, 8])\n",
    "births[summer_mask].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "## Resampling Time Series Data\n",
    "\n",
    "Real-world data often needs to be converted between different time frequencies. Daily data might need to be summarized to monthly for reporting, or minute-level data might be aggregated to hourly for analysis. Pandas' `resample()` method handles these conversions elegantly. Resampling can be thought of as a time-based groupby operation; just as `groupby` splits data by categorical values, `resample` splits data by time periods and applies an aggregation function.\n",
    "\n",
    "The following diagram illustrates how resampling works conceptually:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                  Downsampling: Daily → Monthly                      │\n",
    "│                                                                     │\n",
    "│  Daily Data (31 rows)         Monthly Data (1 row)                  │\n",
    "│  ┌─────────┬────────┐         ┌─────────┬───────────┐               │\n",
    "│  │  Date   │ Births │         │  Month  │ Births    │               │\n",
    "│  ├─────────┼────────┤         ├─────────┼───────────┤               │\n",
    "│  │ Jan-01  │  8,500 │─┐       │ Jan-88  │ 303,492   │               │\n",
    "│  │ Jan-02  │  9,200 │ │       └─────────┴───────────┘               │\n",
    "│  │ Jan-03  │  9,100 │ ├──→ sum() ─────────────────┘                 │\n",
    "│  │   ...   │   ...  │ │                                             │\n",
    "│  │ Jan-31  │  9,800 │─┘       (31 values aggregated to 1)           │\n",
    "│  └─────────┴────────┘                                               │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-41",
   "metadata": {},
   "source": [
    "### Downsampling: From Higher to Lower Frequency\n",
    "\n",
    "*Downsampling* reduces the frequency of data—for example, converting daily data to monthly. Because multiple observations are combined into one, we must specify an aggregation function like `sum()`, `mean()`, `min()`, or `max()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample births data to monthly, computing the sum\n",
    "monthly_births = births['births'].resample('ME').sum()\n",
    "monthly_births.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple aggregations at once\n",
    "monthly_stats = births['births'].resample('ME').agg(['sum', 'mean', 'std'])\n",
    "monthly_stats.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly births totals\n",
    "weekly_births = births['births'].resample('W').sum()\n",
    "weekly_births.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-45",
   "metadata": {},
   "source": [
    "### Yearly Analysis with Real Data\n",
    "\n",
    "Let's analyze birth trends at the yearly level to see long-term patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual birth totals\n",
    "yearly_births = births['births'].resample('YE').sum()\n",
    "yearly_births"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year with most and fewest births\n",
    "print(f\"Year with most births:  {yearly_births.idxmax().year}: {yearly_births.max():,}\")\n",
    "print(f\"Year with fewest births: {yearly_births.idxmin().year}: {yearly_births.min():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-48",
   "metadata": {},
   "source": [
    "### Upsampling: From Lower to Higher Frequency\n",
    "\n",
    "*Upsampling* increases the frequency—converting monthly data to daily, for example. This introduces missing values that must be handled, typically through forward-filling, back-filling, or interpolation. Each approach makes different assumptions about how values change between observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create monthly data for demonstration\n",
    "monthly = pd.Series(\n",
    "    [100, 120, 115, 130],\n",
    "    index=pd.date_range('2024-01-01', periods=4, freq='MS'),\n",
    "    name='monthly_value'\n",
    ")\n",
    "print(\"Original monthly data:\")\n",
    "print(monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample to daily - notice the NaN values\n",
    "daily_upsampled = monthly.resample('D').asfreq()\n",
    "daily_upsampled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward-fill: carry the last known value forward\n",
    "daily_ffill = monthly.resample('D').ffill()\n",
    "daily_ffill.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate: linearly interpolate between known values\n",
    "daily_interp = monthly.resample('D').interpolate()\n",
    "daily_interp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-53",
   "metadata": {},
   "source": [
    "### Choosing an Upsampling Method\n",
    "\n",
    "The choice of fill method depends on the nature of your data and what assumptions are reasonable:\n",
    "\n",
    "| Scenario | Method | Rationale |\n",
    "|----------|--------|----------|\n",
    "| Discrete values (e.g., inventory levels) | `ffill()` | Value stays constant until next observation |\n",
    "| Continuous measures (e.g., temperature) | `interpolate()` | Smooth transitions are realistic |\n",
    "| Need to mark unknowns explicitly | `asfreq()` | Keeps NaN to show missing data |\n",
    "| Categorical or non-numeric | `ffill()` or `bfill()` | Interpolation not applicable |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "## Rolling Statistics and Shifts\n",
    "\n",
    "Time series analysis often requires computing statistics over a sliding window of time—the average of the last 7 days, the maximum of the last 4 weeks, and so on. Pandas provides the `rolling()` method for exactly this purpose. A *rolling window* can be thought of as a sliding frame that moves through your data, computing a statistic at each position. If you imagine looking at your data through a window that shows only the last N observations, and then sliding that window forward one step at a time, you have the intuition for rolling operations.\n",
    "\n",
    "Let's explore rolling statistics using our births data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on a single year for clarity\n",
    "births_1988 = births.loc['1988', 'births']\n",
    "births_1988.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 7-day rolling mean\n",
    "rolling_mean = births_1988.rolling(window=7).mean()\n",
    "rolling_mean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-57",
   "metadata": {},
   "source": [
    "Notice that the first 6 values are `NaN`—the rolling window needs at least 7 observations to compute a mean. You can change this behavior with the `min_periods` parameter, which specifies the minimum number of observations required to produce a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow partial windows with min_periods\n",
    "rolling_mean_partial = births_1988.rolling(window=7, min_periods=1).mean()\n",
    "rolling_mean_partial.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple rolling statistics\n",
    "rolling_df = pd.DataFrame({\n",
    "    'births': births_1988,\n",
    "    'rolling_mean_7d': births_1988.rolling(7).mean(),\n",
    "    'rolling_std_7d': births_1988.rolling(7).std(),\n",
    "    'rolling_min_7d': births_1988.rolling(7).min(),\n",
    "    'rolling_max_7d': births_1988.rolling(7).max()\n",
    "})\n",
    "\n",
    "rolling_df.iloc[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-60",
   "metadata": {},
   "source": [
    "### Time-Based Windows\n",
    "\n",
    "Instead of specifying a number of observations, you can specify a time duration for the window. This is particularly useful when your data has irregular spacing or when you want to express the window in calendar terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14-day rolling window using time offset\n",
    "rolling_14d = births_1988.rolling('14D').mean()\n",
    "rolling_14d.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-62",
   "metadata": {},
   "source": [
    "### Shifting Data with shift()\n",
    "\n",
    "The `shift()` method moves data forward or backward in time. This is essential for computing differences between consecutive time periods, calculating returns, or aligning data for lead/lag analysis. One subtlety to be aware of is that `shift()` moves the *values* while keeping the *index* in place, which results in NaN values at the boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple series for demonstration\n",
    "s = pd.Series([100, 105, 103, 110, 108],\n",
    "              index=pd.date_range('2024-01-01', periods=5, freq='D'),\n",
    "              name='price')\n",
    "\n",
    "print(\"Original:\")\n",
    "print(s)\n",
    "\n",
    "print(\"\\nShifted forward by 1 (lag):\")\n",
    "print(s.shift(1))\n",
    "\n",
    "print(\"\\nShifted backward by 1 (lead):\")\n",
    "print(s.shift(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-64",
   "metadata": {},
   "source": [
    "### Computing Period-over-Period Changes\n",
    "\n",
    "A common application of shifting is computing percentage changes between consecutive periods. While Pandas provides the `pct_change()` method for this, understanding how it relates to `shift()` is instructive. The formula `(current - previous) / previous` translates directly to `(s - s.shift(1)) / s.shift(1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual calculation of daily returns\n",
    "manual_returns = (s - s.shift(1)) / s.shift(1) * 100\n",
    "print(\"Manual calculation:\")\n",
    "print(manual_returns)\n",
    "\n",
    "# Using pct_change() - equivalent result\n",
    "print(\"\\nUsing pct_change():\")\n",
    "print(s.pct_change() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-66",
   "metadata": {},
   "source": [
    "Let's apply this to our real births data to see year-over-year changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year-over-year change in annual births\n",
    "yearly_change = yearly_births.pct_change() * 100\n",
    "yearly_change.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best and worst years for birth rate changes\n",
    "print(f\"Largest increase: {yearly_change.idxmax().year}: {yearly_change.max():.2f}%\")\n",
    "print(f\"Largest decrease: {yearly_change.idxmin().year}: {yearly_change.min():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-69",
   "metadata": {},
   "source": [
    "### Exponentially Weighted Moving Average\n",
    "\n",
    "While simple rolling averages treat all observations in the window equally, you may want more recent observations to have greater influence. The *exponentially weighted moving average* (EWMA) achieves this by assigning exponentially decreasing weights to older observations. This is commonly used in financial analysis and signal processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare simple rolling mean with exponentially weighted mean\n",
    "comparison = pd.DataFrame({\n",
    "    'births': births_1988,\n",
    "    'rolling_7d': births_1988.rolling(7).mean(),\n",
    "    'ewm_span7': births_1988.ewm(span=7).mean()\n",
    "})\n",
    "\n",
    "comparison.iloc[10:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-71",
   "metadata": {},
   "source": [
    "The `span` parameter in `ewm()` roughly corresponds to the window size in `rolling()`—a span of 7 means that older observations' weights decay such that they become negligible after about 7 periods. The exponentially weighted average responds more quickly to recent changes in the data, which is visible when comparing the two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-72",
   "metadata": {},
   "source": [
    "## Choosing the Right Time Series Method\n",
    "\n",
    "With several methods available for time series manipulation, it helps to have clear guidance on when to use each:\n",
    "\n",
    "| Task | Method | When to Use |\n",
    "|------|--------|-------------|\n",
    "| Convert strings to dates | `pd.to_datetime()` | Always the first step with date strings |\n",
    "| Create regular date sequence | `pd.date_range()` | Building time indices, test data |\n",
    "| Reduce frequency (daily→monthly) | `resample().sum/mean()` | Aggregating to coarser granularity |\n",
    "| Increase frequency (monthly→daily) | `resample().ffill/interpolate()` | Filling in finer-grained data |\n",
    "| Smooth data | `rolling().mean()` | Reduce noise, see trends |\n",
    "| Weight recent data more | `ewm().mean()` | Responsive smoothing, momentum |\n",
    "| Compare to previous period | `shift(1)` or `pct_change()` | Calculate changes, returns |\n",
    "| Select by date range | `df.loc['1988-03']` | Intuitive date-based slicing |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-73",
   "metadata": {},
   "source": [
    "## Practical Example: Complete Time Series Analysis\n",
    "\n",
    "Let's bring these concepts together with a comprehensive analysis of the births data, demonstrating how the techniques we've learned work in combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze day-of-week patterns across the full dataset\n",
    "births['day_of_week'] = births.index.day_name()\n",
    "\n",
    "# Average births by day of week\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "births_by_day = births.groupby('day_of_week')['births'].mean().reindex(day_order)\n",
    "births_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal patterns: average births by month\n",
    "births_by_month = births['births'].groupby(births.index.month).mean()\n",
    "births_by_month.index = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                         'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "births_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple time series operations\n",
    "# Monthly average with 12-month rolling average to see long-term trend\n",
    "monthly_avg = births['births'].resample('ME').mean()\n",
    "monthly_rolling = monthly_avg.rolling(12).mean()\n",
    "\n",
    "combined = pd.DataFrame({\n",
    "    'monthly_avg': monthly_avg,\n",
    "    'rolling_12m': monthly_rolling,\n",
    "    'yoy_change_pct': monthly_avg.pct_change(12) * 100\n",
    "})\n",
    "\n",
    "combined.dropna().head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-77",
   "metadata": {},
   "source": [
    "## Practical Pipeline: Time Series Preprocessing\n",
    "\n",
    "To conclude this section, here is a reusable function that combines the key time series concepts we've covered. This pipeline is designed for typical time series preprocessing tasks like those you might encounter in business analytics or scientific analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_time_series(df, date_column=None, value_column='value', \n",
    "                           freq='D', fill_method='ffill', \n",
    "                           rolling_window=7):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline for time series data.\n",
    "    \n",
    "    Combines concepts from this section:\n",
    "    - Datetime conversion and index setting\n",
    "    - Resampling to regular frequency\n",
    "    - Missing value handling\n",
    "    - Rolling statistics computation\n",
    "    - Period-over-period change calculation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Input data with a date column or DatetimeIndex\n",
    "    date_column : str, optional\n",
    "        Column name containing dates. If None, assumes index is already datetime.\n",
    "    value_column : str\n",
    "        Column name containing the values to analyze\n",
    "    freq : str\n",
    "        Target frequency for resampling (e.g., 'D', 'W', 'ME')\n",
    "    fill_method : str\n",
    "        Method for filling gaps: 'ffill', 'bfill', or 'interpolate'\n",
    "    rolling_window : int\n",
    "        Window size for rolling statistics\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Preprocessed data with additional columns:\n",
    "        - rolling_mean: Rolling average\n",
    "        - rolling_std: Rolling standard deviation\n",
    "        - pct_change: Period-over-period percentage change\n",
    "        - ewm_mean: Exponentially weighted moving average\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> births = pd.read_csv('births.csv')\n",
    "    >>> births['date'] = pd.to_datetime(births[['year', 'month', 'day']])\n",
    "    >>> processed = preprocess_time_series(births, 'date', 'births', freq='ME')\n",
    "    >>> processed.head()\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Step 1: Ensure datetime index\n",
    "    if date_column is not None:\n",
    "        result[date_column] = pd.to_datetime(result[date_column])\n",
    "        result = result.set_index(date_column)\n",
    "    \n",
    "    # Step 2: Extract the value series and resample to regular frequency\n",
    "    series = result[value_column].resample(freq).mean()\n",
    "    \n",
    "    # Step 3: Handle missing values\n",
    "    if fill_method == 'interpolate':\n",
    "        series = series.interpolate()\n",
    "    elif fill_method == 'ffill':\n",
    "        series = series.ffill()\n",
    "    elif fill_method == 'bfill':\n",
    "        series = series.bfill()\n",
    "    \n",
    "    # Step 4: Compute rolling statistics\n",
    "    output = pd.DataFrame({\n",
    "        value_column: series,\n",
    "        'rolling_mean': series.rolling(rolling_window, min_periods=1).mean(),\n",
    "        'rolling_std': series.rolling(rolling_window, min_periods=1).std(),\n",
    "        'pct_change': series.pct_change() * 100,\n",
    "        'ewm_mean': series.ewm(span=rolling_window).mean()\n",
    "    })\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the pipeline with births data\n",
    "# Reset index to have date as column for the example\n",
    "births_reset = births.reset_index()\n",
    "births_reset = births_reset.rename(columns={'index': 'date'})\n",
    "\n",
    "processed = preprocess_time_series(\n",
    "    births_reset, \n",
    "    date_column='date', \n",
    "    value_column='births',\n",
    "    freq='ME',\n",
    "    rolling_window=12\n",
    ")\n",
    "\n",
    "processed.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-80",
   "metadata": {},
   "source": [
    "## Common Pitfalls to Avoid\n",
    "\n",
    "Before concluding, it's worth noting a few common mistakes when working with time series in Pandas:\n",
    "\n",
    "One subtlety with `resample()` is that it requires a DatetimeIndex (or a datetime column specified via the `on` parameter). If you try to resample a DataFrame with an integer index, you'll get an error. Always ensure your data has proper datetime indexing before resampling.\n",
    "\n",
    "Another common issue arises with timezone-naive vs timezone-aware datetimes. Mixing them in operations will raise an error. The solution is to either localize naive datetimes with `tz_localize()` or remove timezone info with `tz_localize(None)` to ensure consistency.\n",
    "\n",
    "A helpful pattern to remember:\n",
    "\n",
    "```\n",
    "❌ df.resample('ME').sum()  # Fails if index is not DatetimeIndex\n",
    "\n",
    "✅ df.set_index('date_column').resample('ME').sum()  # Set index first\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-81",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we explored Pandas' comprehensive time series capabilities using real-world data from US birth records:\n",
    "\n",
    "- **Datetime conversion**: Use `pd.to_datetime()` to parse date strings in various formats, with control over ambiguous formats via `dayfirst` and explicit `format` parameters. For multi-column dates, pass a dictionary of columns.\n",
    "\n",
    "- **Date ranges**: Create sequences of dates with `pd.date_range()`, specifying frequencies like daily ('D'), weekly ('W'), monthly ('ME'), or business days ('B').\n",
    "\n",
    "- **Time-based indexing**: Leverage `DatetimeIndex` for intuitive partial string indexing and inclusive date slicing. Selecting `df.loc['1988-03']` returns all March 1988 data.\n",
    "\n",
    "- **Resampling**: Convert between time frequencies using `resample()`, with downsampling (higher to lower frequency) requiring aggregation and upsampling (lower to higher) requiring fill methods.\n",
    "\n",
    "- **Rolling statistics**: Compute moving averages, standard deviations, and other statistics over sliding windows with `rolling()`, and use exponentially weighted functions with `ewm()` when recent observations should carry more weight.\n",
    "\n",
    "- **Shifting and returns**: Use `shift()` to create lagged or leading versions of data, enabling return calculations and lead/lag analysis.\n",
    "\n",
    "These tools form the foundation for sophisticated time series analysis. As we have seen, they integrate seamlessly with Pandas' other capabilities—grouping, aggregation, and data manipulation—enabling comprehensive data analysis workflows. The patterns demonstrated here with birth data apply equally to financial data, sensor readings, web logs, and countless other temporal datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
